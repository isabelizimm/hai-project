{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "microbiology_events = pd.read_csv(\"../data/raw/mimic-iii-demo/MICROBIOLOGYEVENTS.csv\")\n",
    "admission = pd.read_csv(\"../data/raw/mimic-iii-demo/ADMISSIONS.csv\")\n",
    "patient = pd.read_csv(\"../data/raw/mimic-iii-demo/PATIENTS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = pd.merge(admission, patient, \\\n",
    "                        on='subject_id')\n",
    "demographics= pd.merge(demographics, microbiology_events[['org_name','hadm_id']],\\\n",
    "                       on ='hadm_id',\\\n",
    "                       how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabelzimmerman/.local/share/virtualenvs/isabelzimmerman-n-Uyvjwz/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from mlworkflows import featuressimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_summary = featuressimple.SimpleSummaries()\n",
    "\n",
    "summaries = simple_summary.transform(demographics[\"org_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "feat_pipeline = Pipeline([\n",
    "    ('features',simple_summary)\n",
    "])\n",
    "\n",
    "from mlworkflows import util\n",
    "util.serialize_to(feat_pipeline, \"feature_pipeline.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want to our model to attempt to find patterns in the ID number, so we will drop it from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_info = pd.merge(admission, microbiology_events, on='hadm_id')\n",
    "pt_columns = ['admission_type', 'admission_location', 'diagnosis', 'spec_itemid', 'org_itemid','interpretation']\n",
    "pt_info = pt_info.loc[ : , pt_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to gather insight from the data, we have to find out how to translate our information in a way that a machine will understand. We'll use something called a [One Hot Encoder](link) in order to create numeric columns per input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "demographics = demographics.dropna()\n",
    "demographics = demographics.astype('str') \n",
    "\n",
    "# initialize one hot encoder\n",
    "enc = preprocessing.OneHotEncoder(sparse='T', )\n",
    "\n",
    "# fit transforn one hot encoder\n",
    "encoded_demographics = pd.DataFrame(enc.fit_transform(demographics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 0)\\t1.0\\n  (0, 7)\\t1.0\\n  (0, 20)\\t1.0\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 1)\\t1.0\\n  (0, 8)\\t1.0\\n  (0, 17)\\t1.0\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 1)\\t1.0\\n  (0, 8)\\t1.0\\n  (0, 17)\\t1.0\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 1)\\t1.0\\n  (0, 8)\\t1.0\\n  (0, 17)\\t1.0\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 1)\\t1.0\\n  (0, 8)\\t1.0\\n  (0, 17)\\t1.0\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>(0, 5)\\t1.0\\n  (0, 12)\\t1.0\\n  (0, 16)\\t1.0\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>(0, 5)\\t1.0\\n  (0, 12)\\t1.0\\n  (0, 16)\\t1.0\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>(0, 5)\\t1.0\\n  (0, 12)\\t1.0\\n  (0, 16)\\t1.0\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>(0, 5)\\t1.0\\n  (0, 12)\\t1.0\\n  (0, 16)\\t1.0\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 13)\\t1.0\\n  (0, 18)\\t1.0\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0      (0, 0)\\t1.0\\n  (0, 7)\\t1.0\\n  (0, 20)\\t1.0\\n...\n",
       "1      (0, 1)\\t1.0\\n  (0, 8)\\t1.0\\n  (0, 17)\\t1.0\\n...\n",
       "2      (0, 1)\\t1.0\\n  (0, 8)\\t1.0\\n  (0, 17)\\t1.0\\n...\n",
       "3      (0, 1)\\t1.0\\n  (0, 8)\\t1.0\\n  (0, 17)\\t1.0\\n...\n",
       "4      (0, 1)\\t1.0\\n  (0, 8)\\t1.0\\n  (0, 17)\\t1.0\\n...\n",
       "..                                                 ...\n",
       "98     (0, 5)\\t1.0\\n  (0, 12)\\t1.0\\n  (0, 16)\\t1.0\\...\n",
       "99     (0, 5)\\t1.0\\n  (0, 12)\\t1.0\\n  (0, 16)\\t1.0\\...\n",
       "100    (0, 5)\\t1.0\\n  (0, 12)\\t1.0\\n  (0, 16)\\t1.0\\...\n",
       "101    (0, 5)\\t1.0\\n  (0, 12)\\t1.0\\n  (0, 16)\\t1.0\\...\n",
       "102    (0, 6)\\t1.0\\n  (0, 13)\\t1.0\\n  (0, 18)\\t1.0\\...\n",
       "\n",
       "[103 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more reasonable in a different notebook\n",
    "\n",
    "#import sklearn.decomposition \n",
    "#from sklearn.decomposition import PCA\n",
    "\n",
    "#pca = sklearn.decomposition.TruncatedSVD(2)\n",
    "\n",
    "# fit_transform original data, put into data frame\n",
    "#pca_demographics = pca.fit_transform(demographics)\n",
    "#df_pca_demographics = pd.DataFrame(pca_demographics, columns=[\"x\", \"y\"])\n",
    "\n",
    "# transform new spam data, put into data frame\n",
    "#pca_pt_info = pca.fit_transform(pt_info)\n",
    "#df_pca_pt_info = pd.DataFrame(pca_pt_info, columns=[\"x\", \"y\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "train, test = model_selection.train_test_split(encoded_demographics, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 5)\\t1.0\\n  (0, 12)\\t1.0\\n  (0, 16)\\t1.0\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 5)\\t1.0\\n  (0, 12)\\t1.0\\n  (0, 16)\\t1.0\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 5)\\t1.0\\n  (0, 12)\\t1.0\\n  (0, 16)\\t1.0\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 11)\\t1.0\\n  (0, 15)\\t1.0\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 1)\\t1.0\\n  (0, 8)\\t1.0\\n  (0, 17)\\t1.0\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>(0, 3)\\t1.0\\n  (0, 10)\\t1.0\\n  (0, 19)\\t1.0\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>(0, 2)\\t1.0\\n  (0, 9)\\t1.0\\n  (0, 14)\\t1.0\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>(0, 2)\\t1.0\\n  (0, 9)\\t1.0\\n  (0, 14)\\t1.0\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>(0, 3)\\t1.0\\n  (0, 10)\\t1.0\\n  (0, 19)\\t1.0\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>(0, 3)\\t1.0\\n  (0, 10)\\t1.0\\n  (0, 19)\\t1.0\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0     (0, 5)\\t1.0\\n  (0, 12)\\t1.0\\n  (0, 16)\\t1.0\\...\n",
       "1     (0, 5)\\t1.0\\n  (0, 12)\\t1.0\\n  (0, 16)\\t1.0\\...\n",
       "2     (0, 5)\\t1.0\\n  (0, 12)\\t1.0\\n  (0, 16)\\t1.0\\...\n",
       "3     (0, 4)\\t1.0\\n  (0, 11)\\t1.0\\n  (0, 15)\\t1.0\\...\n",
       "4     (0, 1)\\t1.0\\n  (0, 8)\\t1.0\\n  (0, 17)\\t1.0\\n...\n",
       "..                                                ...\n",
       "72    (0, 3)\\t1.0\\n  (0, 10)\\t1.0\\n  (0, 19)\\t1.0\\...\n",
       "73    (0, 2)\\t1.0\\n  (0, 9)\\t1.0\\n  (0, 14)\\t1.0\\n...\n",
       "74    (0, 2)\\t1.0\\n  (0, 9)\\t1.0\\n  (0, 14)\\t1.0\\n...\n",
       "75    (0, 3)\\t1.0\\n  (0, 10)\\t1.0\\n  (0, 19)\\t1.0\\...\n",
       "76    (0, 3)\\t1.0\\n  (0, 10)\\t1.0\\n  (0, 19)\\t1.0\\...\n",
       "\n",
       "[77 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame(train)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "clf = sklearn.svm.SVC()\n",
    "clf.fit(X=train, y=train[\"mrsa_positive\"])\n",
    "clf.fit(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.fit(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlworkflows import plot\n",
    "\n",
    "df, chart = plot.binary_confusion_matrix(test[\"mrsa_positive\"], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test.label.values, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to save the model so that we can use it outside of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlworkflows import util\n",
    "util.serialize_to(model, \"model.sav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
